{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export variables for Taylor Diagrams\n",
    "- This script is used to export variables from simulations and Taylor Diagram metrics;\n",
    "- Simulations: TRAF and sensitity simulations at FR-Capitole and UK-Manchester. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "home_path = '/gws/nopw/j04/duicv/yuansun/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_list = ['summer', 'winter'] \n",
    "factor_list = ['add0.1', 'add0.2', 'add0.4', 'add0.8', 'sub0.1', 'sub0.2', 'sub0.4', 'sub0.8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FR-Capitole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6143 15215\n"
     ]
    }
   ],
   "source": [
    "start = datetime.fromisoformat('2004-02-20T00:30:00')\n",
    "summer_end = datetime.fromisoformat('2004-06-27T00:00:00')  # just an example\n",
    "winter_end = datetime.fromisoformat('2005-01-02T00:00:00')  # just an example\n",
    "\n",
    "interval = timedelta(minutes=30)\n",
    "summer_n_timesteps = int((summer_end - start) / interval)\n",
    "winter_n_timesteps = int((winter_end - start) / interval)\n",
    "print(summer_n_timesteps, winter_n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = ['2004-06-27-01800', '2005-01-02-01800']\n",
    "start_date_list = ['2004-06-27T00:00:00', '2005-01-02T00:00:00']\n",
    "end_date_list = ['2004-07-04T00:00:00', '2005-01-09T00:00:00']\n",
    "season_list = ['summer', 'winter']\n",
    "var1 = ['LWup', 'Qh', 'Qle', 'Qtau']\n",
    "var2 = ['FIRE_U', 'FSH_U', 'EFLX_LH_TOT_U', 'TAUX']\n",
    "rename_dict = dict(zip(var2, var1))\n",
    "GRIDNAME='FR-Capitole'\n",
    "gridname='FR-Cap'\n",
    "observation = f'{home_path}0_lcz_sp/UrbanPlumber/Urban-PLUMBER_FullCollection_v1/' + GRIDNAME + '/timeseries/'+ GRIDNAME + '_clean_observations_v1.nc'\n",
    "ds_ob = xr.open_dataset(observation)\n",
    "ds_traffic = xr.open_dataset(f'{home_path}0_urban_traffic/archive/{gridname}_traffic/lnd/hist/{gridname}_traffic.clm2.h0.2004-02-20-03600.nc')\n",
    "for p, period in enumerate(period_list):\n",
    "    ds_ob_sel = ds_ob.sel(time=slice(start_date_list[p], end_date_list[p]))\n",
    "    df_obs = ds_ob_sel[var1].to_dataframe().reset_index()\n",
    "    df_obs['case'] = 'obs'\n",
    "    #df_obs = df_obs.iloc[:-1]\n",
    "    df_obs=df_obs.iloc[1:]\n",
    "    season = season_list[p]\n",
    "    casename = f'{gridname}_{season}'\n",
    "    date = date_list[p]\n",
    "    all_dfs = [df_obs]\n",
    "    ds_traffic_sel = ds_traffic.sel(time=slice(start_date_list[p], end_date_list[p]))\n",
    "    df_traffic = ds_traffic_sel[var2].to_dataframe().reset_index()\n",
    "    df_traffic['time'] = pd.to_datetime(df_traffic['time'])\n",
    "    df_traffic['time'] = df_traffic['time'].dt.round('min').dt.ceil('min')\n",
    "    df_traffic.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_traffic = df_traffic.rename(columns=rename_dict) \n",
    "    df_traffic['case'] = 'traffic'\n",
    "    df_traffic['Qtau'] = -df_traffic['Qtau']\n",
    "    df_traffic=df_traffic.iloc[1:]\n",
    "    for factor in factor_list:\n",
    "        ds_factor = xr.open_dataset(f'{home_path}0_urban_traffic/archive/sensitivity/{casename}/{casename}.clm2.h0.{date}_{factor}.nc')\n",
    "        df_factor = ds_factor[var2].to_dataframe().reset_index()\n",
    "        df_factor['time'] = pd.to_datetime(df_factor['time'])\n",
    "        df_factor['time'] = df_factor['time'].dt.round('min').dt.ceil('min')\n",
    "        df_factor.drop(columns=['lndgrid'], inplace=True)\n",
    "        df_factor = df_factor.rename(columns=rename_dict) \n",
    "        df_factor['case'] = factor\n",
    "        df_factor['Qtau'] = -df_factor['Qtau']\n",
    "        all_dfs.append(df_factor)\n",
    "    all_dfs.append(df_traffic)    \n",
    "    df_combined = pd.concat(all_dfs, ignore_index=True)        \n",
    "   # df_combined.to_csv(f'./output/{GRIDNAME}_{season}.csv', index=False)\n",
    "    df_combined.head()               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK-Manchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704 8232\n"
     ]
    }
   ],
   "source": [
    "start = datetime.fromisoformat('2022-01-01T00:00:00')\n",
    "summer_end = datetime.fromisoformat('2022-07-16T00:00:00')  # just an example\n",
    "winter_end = datetime.fromisoformat('2022-12-10T00:00:00')  # just an example\n",
    "\n",
    "interval = timedelta(minutes=60)\n",
    "summer_n_timesteps = int((summer_end - start) / interval)\n",
    "winter_n_timesteps = int((winter_end - start) / interval)\n",
    "print(summer_n_timesteps, winter_n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rh_hourly_avg</th>\n",
       "      <th>temp_hourly_avg</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>std_temp_bias</th>\n",
       "      <th>std_rh_bias</th>\n",
       "      <th>rh_hourly_avg_corrected</th>\n",
       "      <th>temp_hourly_avg_temp</th>\n",
       "      <th>temp_hourly_avg_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-21 14:00:00</td>\n",
       "      <td>43.610000</td>\n",
       "      <td>17.06000</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.196525</td>\n",
       "      <td>-0.182844</td>\n",
       "      <td>51.583847</td>\n",
       "      <td>13.707289</td>\n",
       "      <td>13.707289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-21 15:00:00</td>\n",
       "      <td>39.354386</td>\n",
       "      <td>18.73386</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>-0.178718</td>\n",
       "      <td>46.387718</td>\n",
       "      <td>15.149258</td>\n",
       "      <td>15.149258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-21 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.176080</td>\n",
       "      <td>-0.158543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-21 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156802</td>\n",
       "      <td>-0.136305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-21 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148477</td>\n",
       "      <td>-0.124433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  rh_hourly_avg  temp_hourly_avg  hour  month  \\\n",
       "0  2022-02-21 14:00:00      43.610000         17.06000    14      2   \n",
       "1  2022-02-21 15:00:00      39.354386         18.73386    15      2   \n",
       "2  2022-02-21 16:00:00            NaN              NaN    16      2   \n",
       "3  2022-02-21 17:00:00            NaN              NaN    17      2   \n",
       "4  2022-02-21 18:00:00            NaN              NaN    18      2   \n",
       "\n",
       "   std_temp_bias  std_rh_bias  rh_hourly_avg_corrected  temp_hourly_avg_temp  \\\n",
       "0       0.196525    -0.182844                51.583847             13.707289   \n",
       "1       0.191343    -0.178718                46.387718             15.149258   \n",
       "2       0.176080    -0.158543                      NaN                   NaN   \n",
       "3       0.156802    -0.136305                      NaN                   NaN   \n",
       "4       0.148477    -0.124433                      NaN                   NaN   \n",
       "\n",
       "   temp_hourly_avg_corrected  \n",
       "0                  13.707289  \n",
       "1                  15.149258  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_id = 'MOD-PM-00427'\n",
    "df_sensor = pd.read_csv(f'{home_path}0_lcz_mcr/output_analysis/single_point/calibration/adjusted_sensor_data/{sensor_id}.csv')\n",
    "df_sensor.rename(columns={'timestamp': 'time'}, inplace=True)\n",
    "df_sensor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = ['2022-07-16-03600', '2022-12-10-03600']\n",
    "start_date_list = ['2022-07-15T00:00:00', '2022-12-09T00:00:00']\n",
    "start_date_list2 = ['2022-07-16T01:00:00', '2022-12-10T01:00:00']\n",
    "end_date_list = ['2022-07-23-T00:00:00', '2022-12-17T00:00:00']\n",
    "var3 = ['temp_hourly_avg_corrected', 'rh_hourly_avg_corrected']\n",
    "var4 = ['TSA_U', 'RH2M']\n",
    "rename_dict = dict(zip(var3, var4))\n",
    "GRIDNAME='UK-MCR'\n",
    "\n",
    "ds_traffic = xr.open_dataset(f'{home_path}0_urban_traffic/archive/{GRIDNAME}_traffic/lnd/hist/{GRIDNAME}_traffic.clm2.h0.2022-01-01-03600.nc')\n",
    "for p, period in enumerate(period_list):\n",
    "    df_obs = df_sensor[(df_sensor['time']>=start_date_list[p]) & (df_sensor['time']<=end_date_list[p])].reset_index(drop=True)\n",
    "    df_obs_sel = df_obs[['time'] + var3][1:-23].reset_index(drop=True)\n",
    "    df_obs_sel['time']= pd.to_datetime(df_obs_sel['time'])\n",
    "    df_obs_sel.rename(columns=rename_dict, inplace=True)\n",
    "    df_obs_sel['case'] = 'obs'\n",
    "    season = season_list[p]\n",
    "    casename = f'{GRIDNAME}_{season}'\n",
    "    date = date_list[p]\n",
    "    all_dfs = [df_obs_sel]\n",
    "    ds_traffic_sel = ds_traffic.sel(time=slice(start_date_list2[p], end_date_list[p]))\n",
    "    df_traffic = ds_traffic_sel[var2].to_dataframe().reset_index()\n",
    "    df_traffic.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_traffic['time'] = df_traffic['time'].dt.round('min').dt.ceil('min')\n",
    "    df_traffic['case'] = 'traffic'\n",
    "    df_traffic['TSA_U'] = df_traffic['TSA_U'] -273.15\n",
    "    for factor in factor_list:\n",
    "        ds_factor = xr.open_dataset(f'{home_path}0_urban_traffic/archive/sensitivity/{casename}/{casename}.clm2.h0.{date}_{factor}.nc')\n",
    "        df_factor = ds_factor[var4].to_dataframe().reset_index()\n",
    "        df_factor['time'] = pd.to_datetime(df_factor['time'])\n",
    "        df_factor['time'] = df_factor['time'].dt.round('min').dt.ceil('min')\n",
    "        df_factor.drop(columns=['lndgrid'], inplace=True)\n",
    "        df_factor['case'] = factor\n",
    "        df_factor['TSA_U'] = df_factor['TSA_U'] -273.15\n",
    "        all_dfs.append(df_factor)\n",
    "    all_dfs.append(df_traffic)    \n",
    "    df_combined = pd.concat(all_dfs, ignore_index=True)        \n",
    "    df_combined.to_csv(f'./output/{GRIDNAME}_{season}.csv', index=False)\n",
    "    df_combined.head()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taylor diagram metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_list = factor_list + ['traffic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRIDNAME='FR-Capitole'\n",
    "for season in season_list:\n",
    "    df_combined = pd.read_csv(f'./output/{GRIDNAME}_{season}.csv')\n",
    "    df_obs = df_combined[df_combined['case'] == 'obs'].reset_index(drop=True)\n",
    "    std_result = []\n",
    "    coef_result = []\n",
    "    for factor in case_list:\n",
    "        df_factor = df_combined[df_combined['case'] == factor].reset_index(drop=True)\n",
    "        for var in var1:\n",
    "            df_sim = df_factor[['time', var]].copy()\n",
    "            df_sim = df_sim.rename(columns={var: 'sim'})\n",
    "            df_sim['obs'] = df_obs[var]\n",
    "            df_sim.loc[df_sim['obs'].isna(), ['sim']] = np.nan\n",
    "            df_sim.dropna(subset=['obs', 'sim'], inplace=True)\n",
    "            std = float(np.std(df_sim['sim']))\n",
    "            sdev = std/float(np.std(df_sim['obs']))\n",
    "            coef = float(xr.corr(xr.DataArray(df_sim['obs']), xr.DataArray(df_sim['sim'])).values)\n",
    "            std_result.append(sdev)\n",
    "            coef_result.append(coef)\n",
    "    df = pd.DataFrame({'factor': np.repeat(case_list, len(var1)), 'var': var1 * len(case_list), 'sdev': std_result, 'coef': coef_result})  \n",
    "    df.to_csv(f'./data_for_figure/{GRIDNAME}_{season}_std_coef.csv', index=False)      \n",
    "    df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRIDNAME='UK-MCR'\n",
    "for season in season_list:\n",
    "    df_combined = pd.read_csv(f'./output/{GRIDNAME}_{season}.csv')\n",
    "    df_obs = df_combined[df_combined['case'] == 'obs'].reset_index(drop=True)\n",
    "    std_result = []\n",
    "    coef_result = []\n",
    "    for factor in case_list:\n",
    "        df_factor = df_combined[df_combined['case'] == factor].reset_index(drop=True)\n",
    "        for var in var4:\n",
    "            df_sim = df_factor[['time', var]].copy()\n",
    "            df_sim = df_sim.rename(columns={var: 'sim'})\n",
    "            df_sim['obs'] = df_obs[var]\n",
    "            df_sim.loc[df_sim['obs'].isna(), ['sim']] = np.nan\n",
    "            df_sim.dropna(subset=['obs', 'sim'], inplace=True)\n",
    "            std = float(np.std(df_sim['sim']))\n",
    "            sdev = std/float(np.std(df_sim['obs']))\n",
    "            coef = float(xr.corr(xr.DataArray(df_sim['obs']), xr.DataArray(df_sim['sim'])).values)\n",
    "            std_result.append(sdev)\n",
    "            coef_result.append(coef)\n",
    "    df = pd.DataFrame({'factor': np.repeat(case_list, len(var4)), 'var': var4 * len(case_list), 'sdev': std_result, 'coef': coef_result})  \n",
    "    df.to_csv(f'./data_for_figure/{GRIDNAME}_{season}_std_coef.csv', index=False)      \n",
    "    df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
